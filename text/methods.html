<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Methods: Dominance index – 100 billion dollar COP-out</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../text/findings.html" rel="next">
<link href="../text/theory.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea6fd3121155f662d4b42a67aec36ccf.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b23120bae58a0bb65cf2ab8f87be3cc8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../text/theory.html">Research design</a></li><li class="breadcrumb-item"><a href="../text/methods.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Methods: Dominance index</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">100 billion dollar COP-out</a> 
        <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../100-billion-dollar-COP-out.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="../100-billion-dollar-COP-out.docx">
              <i class="bi bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstract</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Climate adaptation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/context.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Context: Climate action</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/lit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Literature review: Nexus and regime</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Research design</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Theory: Development Ontology and Epistemological Diversity</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Methods: Dominance index</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/findings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Findings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../text/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#corpus-collection-and-preparation" id="toc-corpus-collection-and-preparation" class="nav-link active" data-scroll-target="#corpus-collection-and-preparation"><span class="header-section-number">5.1</span> Corpus collection and preparation</a></li>
  <li><a href="#structural-topic-modeling" id="toc-structural-topic-modeling" class="nav-link" data-scroll-target="#structural-topic-modeling"><span class="header-section-number">5.2</span> Structural topic modeling</a></li>
  <li><a href="#dominance-index-calculation" id="toc-dominance-index-calculation" class="nav-link" data-scroll-target="#dominance-index-calculation"><span class="header-section-number">5.3</span> Dominance Index calculation</a></li>
  <li><a href="#visualization-and-interpretation" id="toc-visualization-and-interpretation" class="nav-link" data-scroll-target="#visualization-and-interpretation"><span class="header-section-number">5.4</span> Visualization and interpretation</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../text/theory.html">Research design</a></li><li class="breadcrumb-item"><a href="../text/methods.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Methods: Dominance index</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Methods: Dominance index</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>To analyze discourse centralization in climate adaptation, I develop a methodological approach centered around the “Dominance Index”—a measurement tool for quantifying the degree to which adaptation discourse is concentrated around particular topics or perspectives. This approach combines structural topic modeling of National Adaptation Plans with calculations of topic dominance to identify patterns in how adaptation is conceptualized across different contexts.</p>
<p>The methodology bridges critical theoretical perspectives with quantitative text analysis, creating an interdisciplinary approach that can systematically analyze discourse patterns across a substantial corpus of documents. Rather than assuming either complete homogeneity or radical diversity in adaptation discourse, this approach enables empirical assessment of the degree to which discourse reflects epistemological plurality or monoculture across different contexts.</p>
<p>This methodological approach can measure the distribution of topics across documents and document groups, identifying patterns of concentration or dispersion. However, it cannot directly measure epistemological diversity—topic distribution serves as a proxy that requires careful interpretation. The approach does not capture discourse elements that may not be reflected in word co-occurrence patterns, such as rhetorical structures, implicit assumptions, or visual elements of the documents.</p>
<p>The primary corpus consists of National Adaptation Plans (NAPs) submitted to the UNFCCC—official policy documents that outline countries’ approaches to climate adaptation. These documents represent a particularly revealing window into adaptation discourse because they are produced through standardized international frameworks while addressing context-specific national priorities. The NAPs are prepared by national governments in consultation with various stakeholders and experts, and they outline adaptation priorities, strategies, and planned actions.</p>
<p>This corpus provides several advantages for comparative analysis. First, NAPs follow a relatively standardized format defined by UNFCCC guidelines, creating a consistent basis for comparison across countries. Second, they represent official national positions rather than individual perspectives, making them relevant for understanding national-level discourse patterns. Third, they cover a diverse range of countries across different regions, income levels, and vulnerability profiles, enabling meaningful comparative analysis.</p>
<p>However, the focus on NAPs also has important limitations. As official government documents, NAPs represent formal institutional discourse rather than the full range of adaptation perspectives within a country. They may exclude or marginalize viewpoints from civil society, local communities, or groups with limited access to formal planning processes. Moreover, NAPs are produced within the constraints of UNFCCC frameworks and often with support from international consultants, potentially introducing homogenizing influences from the outset.</p>
<p>This methodological approach involves four main steps:</p>
<ol type="1">
<li><p><strong>Corpus collection and preparation</strong>: Gathering NAP documents and processing them for analysis, including tokenization, stop word removal, lemmatization, and creation of a document-term matrix.</p></li>
<li><p><strong>Structural topic modeling</strong>: Applying computational techniques to identify latent topics in the corpus and examine how these topics vary across different document characteristics.</p></li>
<li><p><strong>Dominance Index calculation</strong>: Developing a quantitative measure of discourse centralization based on the concentration of top topics in different document groups.</p></li>
<li><p><strong>Visualization and interpretation</strong>: Creating visual representations of discourse patterns and interpreting these patterns through the theoretical framework developed in the previous chapter.</p></li>
</ol>
<p>Each of these steps involves specific methodological choices and techniques that shape the analysis, which I elaborate in the following sections.</p>
<p>[visualization placeholder - methodology flowchart]</p>
<p>The approach outlined here draws on both computational text analysis methods, particularly topic modeling <span class="citation" data-cites="roberts2019">(<a href="conclusion.html#ref-roberts2019" role="doc-biblioref">Roberts et al., 2019</a>)</span>, and critical discourse analysis traditions that examine how discourse reflects and reproduces power relations <span class="citation" data-cites="fairclough2013">(<a href="conclusion.html#ref-fairclough2013" role="doc-biblioref"><strong>fairclough2013?</strong></a>)</span>. By combining these approaches, I aim to leverage the systematic analytical capabilities of computational methods while maintaining critical awareness of the political and epistemological dimensions of adaptation discourse.</p>
<section id="corpus-collection-and-preparation" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="corpus-collection-and-preparation"><span class="header-section-number">5.1</span> Corpus collection and preparation</h2>
<p>The corpus consists of 45 English-language National Adaptation Plans (NAPs) submitted to the UNFCCC as of March 2025. These documents represent a diverse range of countries across different regions, income levels, and vulnerability profiles. The documents were collected directly from the UNFCCC NAP Central website (napcentral.org), which serves as the official repository for submitted NAPs.</p>
<p>The focus on English-language documents is a significant methodological constraint. It excludes NAPs submitted in other languages (particularly French and Spanish), potentially skewing the analysis toward Anglophone countries or those with stronger ties to international institutions where English is dominant. This limitation means the analysis cannot claim to represent the full global landscape of adaptation discourse but rather offers insights into patterns within the English-language subset of NAPs.</p>
<p>Despite this limitation, the corpus includes substantial representation from diverse global contexts:</p>
<ul>
<li>18 documents from Africa (40% of the corpus)</li>
<li>14 documents from Asia-Pacific (31% of the corpus)</li>
<li>11 documents from Latin America and Caribbean (24% of the corpus)</li>
<li>2 documents from Europe (4% of the corpus)</li>
</ul>
<p>In terms of income classification:</p>
<ul>
<li>13 from Low-Income Countries (29% of the corpus)</li>
<li>19 from Lower-Middle Income Countries (42% of the corpus)</li>
<li>11 from Upper-Middle Income Countries (24% of the corpus)</li>
<li>2 from High-Income Countries (4% of the corpus)</li>
</ul>
<p>The corpus also includes 15 Least Developed Countries (LDCs), 8 Small Island Developing States (SIDS), and 7 Landlocked Developing Countries (LLDCs), with some countries belonging to multiple special status categories.</p>
<p>Each document is tagged with relevant metadata drawn from World Bank classifications and UNFCCC designations. This metadata includes:</p>
<ul>
<li>Geographic region (Africa, Asia-Pacific, Latin America and Caribbean, Europe)</li>
<li>Income level (Low, Lower-middle, Upper-middle, High)</li>
<li>Special status (SIDS, LDC, LLDC, non-special)</li>
<li>Submission date</li>
<li>Document length</li>
</ul>
<p>The collection of this metadata enables systematic comparison of discourse patterns across different country groupings to identify potential factors influencing how adaptation is conceptualized. The metadata is stored separately from the document text to prevent it from influencing the topic modeling process itself.</p>
<p>Document preparation involves multiple stages of processing to convert the raw NAP documents into a format suitable for computational analysis. This begins with extracting the text content from PDF documents, which presents technical challenges including handling of complex formatting, tables, figures, and inconsistent document structures. I use PDF extraction tools combined with manual verification to ensure accurate text extraction.</p>
<p>Once extracted, the text undergoes several preprocessing steps:</p>
<ol type="1">
<li><p><strong>Tokenization</strong>: Breaking the text into individual words or tokens, which represent the basic units of analysis. This process includes removing punctuation, standardizing capitalization, and handling hyphenation.</p></li>
<li><p><strong>Stop word removal</strong>: Eliminating common words (e.g., “the,” “is,” “and”) that carry little semantic meaning but appear frequently in the text. I remove both standard English stop words and domain-specific terms that appear across all documents but provide limited analytical value due to their ubiquity. These domain-specific stop words include terms like “adaptation,” “climate,” “plan,” “national,” “country,” and “UNFCCC,” which are so common in the corpus that they do not help differentiate between different conceptualizations of adaptation.</p></li>
<li><p><strong>Lemmatization</strong>: Reducing words to their base or dictionary form to treat variations of the same word as a single unit. For example, “adapting,” “adapts,” and “adapted” all become “adapt.” This process helps reduce dimensionality and improve the signal-to-noise ratio in the data.</p></li>
<li><p><strong>Creation of document-term matrix</strong>: Organizing the processed text into a matrix that represents the frequency of each term in each document. This matrix serves as the primary input for the subsequent topic modeling.</p></li>
</ol>
<p>These preprocessing steps enable computational analysis but also involve certain trade-offs. Tokenization breaks text into individual words, losing information about phrasal meanings and sentence structures. Stop word removal eliminates words that, while common, might carry important functional meanings in certain contexts. Lemmatization may obscure subtle distinctions in how terms are used (e.g., converting both “developed” and “developing” to “develop,” potentially blurring an important distinction in climate discourse).</p>
<p>To address some of these limitations, I retain the original text alongside the processed version, allowing for contextual verification when interpreting model outputs. I also conduct sensitivity analyses with different preprocessing choices to ensure that key findings are not artifacts of particular preprocessing decisions.</p>
<p>The final processed corpus contains approximately 3.5 million words across the 45 documents, with an average of 78,000 words per document. Document length varies considerably, from around 20,000 words for the shortest NAP to over 150,000 words for the longest, reflecting differences in both detail and scope across different national contexts. The preprocessing reduces this to approximately 1.2 million tokens representing about 25,000 unique terms, which form the basis for the subsequent topic modeling.</p>
</section>
<section id="structural-topic-modeling" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="structural-topic-modeling"><span class="header-section-number">5.2</span> Structural topic modeling</h2>
<p>To identify patterns in how adaptation is conceptualized across different NAPs, I employ structural topic modeling (STM), a computational technique that identifies latent topics in a corpus and allows for the incorporation of document metadata as predictors of topic prevalence <span class="citation" data-cites="roberts2019">(<a href="conclusion.html#ref-roberts2019" role="doc-biblioref">Roberts et al., 2019</a>)</span>. Unlike simpler forms of topic modeling, STM enables examination of how topic prevalence varies with document characteristics like region or income level, making it particularly suitable for comparative analysis of adaptation discourse.</p>
<p>Topic models are unsupervised machine learning methods that discover abstract “topics” that occur in a collection of documents. The fundamental assumption of topic modeling is that documents are mixtures of topics, where a topic is a probability distribution over words. Each document can be described as a mixture of topics, with certain topics more prevalent than others in each document.</p>
<p>The STM algorithm processes the document-term matrix to identify clusters of words that frequently co-occur, representing coherent topics within the corpus. Mathematically, STM represents each document as a mixture of k topics, with each topic defined as a distribution over the vocabulary. The model simultaneous estimates topic content (the words associated with each topic) and topic prevalence (the proportion of each document devoted to each topic) using a variational expectation-maximization algorithm <span class="citation" data-cites="roberts2019">(<a href="conclusion.html#ref-roberts2019" role="doc-biblioref">Roberts et al., 2019</a>)</span>.</p>
<p>What distinguishes STM from other topic modeling approaches is its ability to incorporate document metadata as covariates that can affect either topic content or topic prevalence. This allows us to examine, for example, how topic prevalence varies across different regions or income levels, or how the content of similar topics might differ across these categories. In this analysis, I focus primarily on topic prevalence covariates, examining how the distribution of topics varies across different document characteristics.</p>
<p>A key methodological decision in topic modeling is determining the appropriate number of topics (k). Too few topics may obscure important distinctions in the corpus, while too many may result in incoherent or redundant topics that are difficult to interpret. I employ a data-driven approach to identify the optimal number of topics, using several metrics:</p>
<ul>
<li><p><strong>Semantic coherence</strong>: Measures the degree to which high-probability words for a topic tend to co-occur in documents. Higher semantic coherence suggests more coherent, interpretable topics.</p></li>
<li><p><strong>Exclusivity</strong>: Measures the degree to which words are exclusive to particular topics rather than appearing across many topics. Higher exclusivity suggests more distinctive topics.</p></li>
<li><p><strong>Held-out likelihood</strong>: Measures the model’s ability to predict held-out text not used in training, providing an indication of how well the model generalizes.</p></li>
</ul>
<p>In addition to these standard metrics, I incorporate a complexity factor that penalizes models with higher numbers of topics. This complexity penalty acknowledges that additional topics introduce greater interpretive challenges without necessarily improving model performance in a meaningful way. The penalty is calculated as a linear function of k, with the specific coefficient determined through experimentation.</p>
<p>After testing models with k ranging from 20 to 80, I select a model with 40 topics based on the balance of semantic coherence, exclusivity, and the complexity penalty. This represents a middle ground that captures meaningful variation in the corpus while maintaining interpretability. The final model is trained using the spectral initialization method, which provides more consistent results than random initialization, and with 100 iterations of the variational expectation-maximization algorithm to ensure convergence.</p>
<p>It’s important to recognize what topic models can and cannot tell us. Topics identified through this process are statistical constructs representing patterns of word co-occurrence. They do not inherently align with human-intuitive conceptual categories, nor do they capture all aspects of discourse such as narrative structure, rhetorical devices, or implicit assumptions. The topics are also specific to this corpus—they represent patterns within the NAPs rather than universal categories of adaptation discourse.</p>
<p>For the top topics identified in the model, I provide tentative interpretations based on:</p>
<ol type="1">
<li>The highest probability words for each topic</li>
<li>The most distinctive words for each topic (using FREX: FRequency and EXclusivity)</li>
<li>Representative documents with high proportions of the topic</li>
<li>Examination of the original context in which topic-associated words appear</li>
</ol>
<p>[visualization placeholder - topic word cloud]</p>
<p>These interpretations should be understood as plausible readings rather than definitive meanings. They aim to translate statistical patterns into conceptually meaningful categories to facilitate interpretation of discourse patterns, while acknowledging the interpretive judgment involved in this translation.</p>
<p>The resulting topic model provides several outputs for analysis:</p>
<ol type="1">
<li><p><strong>Topic-word distributions</strong>: The probability of each word being generated by each topic, which helps interpret what each topic represents.</p></li>
<li><p><strong>Document-topic proportions</strong>: The estimated proportion of each document devoted to each topic, which forms the basis for the Dominance Index.</p></li>
<li><p><strong>Metadata correlations</strong>: How document characteristics like region or income level correlate with topic prevalence, which helps identify patterns across different contexts.</p></li>
<li><p><strong>Topic correlation matrix</strong>: How different topics relate to each other, which can reveal broader thematic clusters within the discourse.</p></li>
</ol>
<p>These outputs enable systematic analysis of patterns in adaptation discourse across different contexts. Rather than imposing predetermined categories or frameworks, this approach allows patterns to emerge inductively from the text while still enabling structured comparison through metadata. The topic model thus serves as a bridge between the unstructured text of the NAPs and the more structured analysis of discourse centralization through the Dominance Index.</p>
</section>
<section id="dominance-index-calculation" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="dominance-index-calculation"><span class="header-section-number">5.3</span> Dominance Index calculation</h2>
<p>To quantify the degree of discourse centralization, I develop a Dominance Index that measures how concentrated or dispersed topic distributions are across different groups of documents. The index provides a single metric that can be compared across different contexts to identify variations in discourse centralization. A high Dominance Index indicates that a few topics dominate the discourse, suggesting a more homogeneous conceptualization of adaptation. A low Dominance Index indicates a more even distribution of topics, suggesting greater diversity in how adaptation is conceptualized.</p>
<p>The Dominance Index focuses specifically on the concentration of the top n topics in a given group of documents. This approach directly addresses the core question of whether adaptation discourse is dominated by a small number of topics or distributed across many different topics. After testing different values, I select n=5 as capturing a significant portion of the discourse while maintaining meaningful distinctions between different contexts.</p>
<p>The calculation of the Dominance Index follows these steps:</p>
<ol type="1">
<li><p><strong>Group documents</strong>: Aggregate documents according to relevant characteristics (e.g., all documents from a particular region or income level).</p></li>
<li><p><strong>Calculate topic proportions</strong>: For each topic, calculate the average proportion across all documents in the group. This gives us the average prevalence of each topic within that group.</p></li>
<li><p><strong>Rank topics</strong>: Sort topics by their average proportion in descending order to identify the most prevalent topics in the group.</p></li>
<li><p><strong>Calculate top-n proportion</strong>: Sum the proportions of the top 5 topics to determine what fraction of the discourse they represent collectively.</p></li>
<li><p><strong>Normalize the index</strong>: Scale the result to a 0-1 range, where 0 represents a perfectly even distribution across all topics and 1 represents complete concentration in a single topic.</p></li>
</ol>
<p>The mathematical formula for the Dominance Index (DI) can be expressed as:</p>
<p>DI = (sum of proportions for top 5 topics - minimum possible sum) / (maximum possible sum - minimum possible sum)</p>
<p>Where:</p>
<ul>
<li>The minimum possible sum would be 5 * (1/k) in a perfectly even distribution across all k topics</li>
<li>The maximum possible sum would be 1 (if all discourse were concentrated in a single topic)</li>
</ul>
<p>This normalization ensures that the Dominance Index is comparable across different values of k and n, though in this analysis both are fixed (k=40, n=5).</p>
<p>The Dominance Index approach differs from entropy-based measures that are sometimes used to quantify diversity in topic distributions. While entropy measures capture the overall evenness of a distribution, the Dominance Index focuses specifically on the concentration of the most prevalent topics, which more directly addresses the question of discourse centralization. The top-n approach also offers greater interpretability, as it can be directly related to specific topics that dominate the discourse.</p>
<p>To address potential biases from uneven document lengths or sample sizes, I implement several controls:</p>
<ol type="1">
<li><p><strong>Document length normalization</strong>: Topic proportions are calculated as fractions of each document, controlling for differences in document length.</p></li>
<li><p><strong>Jackknife resampling</strong>: For groups with more than five documents, I use jackknife resampling (leave-one-out) to assess the stability of the Dominance Index and calculate confidence intervals.</p></li>
<li><p><strong>Sample size thresholds</strong>: For very small groups (fewer than three documents), I flag the results as potentially less reliable and interpret them with greater caution.</p></li>
</ol>
<p>These controls help ensure that the Dominance Index reflects genuine patterns of discourse centralization rather than artifacts of the corpus composition. However, they cannot entirely eliminate the influence of sample size disparities, particularly for the smallest groups.</p>
<p>The Dominance Index enables systematic comparison of discourse centralization across different groupings:</p>
<ul>
<li>Regional groups (Africa, Asia-Pacific, Latin America and Caribbean, Europe)</li>
<li>Income levels (Low, Lower-middle, Upper-middle, High)</li>
<li>Special status designations (SIDS, LDCs, LLDCs, non-special)</li>
<li>The corpus as a whole (providing a baseline for comparison)</li>
</ul>
<p>[visualization placeholder - dominance index comparison chart]</p>
<p>This comparative approach helps identify factors that might influence the degree of epistemological diversity in adaptation discourse. For example, if the Dominance Index varies significantly across regions but not across income levels, this might suggest that regional knowledge systems or institutional frameworks play a more important role in shaping adaptation discourse than economic circumstances.</p>
<p>However, it’s important to specify what the Dominance Index can and cannot tell us. The index measures the concentration of topics in a document group, which serves as a proxy for discourse centralization. A higher concentration (higher Dominance Index) suggests a more centralized discourse, while a lower concentration suggests a more diverse discourse. But this metric does not directly measure epistemological diversity or the substantive content of the discourse. Topic diversity is not necessarily equivalent to epistemological diversity—a discourse might include many different topics while still operating within a single epistemological framework.</p>
<p>Moreover, the Dominance Index doesn’t tell us whether a particular pattern of centralization is “good” or “bad” from a normative perspective. A highly centralized discourse might reflect genuine consensus around effective approaches, while a highly diverse discourse might reflect fragmentation or lack of coherence. Interpreting the normative implications of different Dominance Index values requires connecting the quantitative results to the substantive content of the topics and the broader theoretical framework.</p>
</section>
<section id="visualization-and-interpretation" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="visualization-and-interpretation"><span class="header-section-number">5.4</span> Visualization and interpretation</h2>
<p>To make patterns of discourse centralization more accessible and interpretable, I develop visualization techniques that complement the quantitative analysis. These visualizations serve both analytical and communicative purposes, helping to identify patterns in the data and effectively convey these patterns to readers who may not be familiar with the technical details of topic modeling or the Dominance Index.</p>
<p>The primary visualization approach is a “bullseye” representation of discourse dominance. This visualization places topics as points on a target diagram, with distance from the center determined by the topic’s prevalence. In highly centralized discourse (high Dominance Index), points cluster near the center, indicating that a few topics dominate. In more decentralized discourse (low Dominance Index), points are more evenly distributed throughout the target, indicating greater diversity of topics.</p>
<p>The bullseye visualization is constructed as follows:</p>
<ol type="1">
<li><p>The diagram is divided into concentric rings, with the innermost ring representing the highest topic prevalence and the outermost ring representing the lowest.</p></li>
<li><p>Topics are positioned based on their average proportion within the document group, with more prevalent topics placed closer to the center.</p></li>
<li><p>Each topic is represented by a point, with optional labeling for the most prevalent topics to aid interpretation.</p></li>
<li><p>Color coding can be used to distinguish different types of topics (e.g., based on thematic categories) or to indicate topic correlations.</p></li>
</ol>
<p>[visualization placeholder - bullseye diagram]</p>
<p>This visual representation provides an intuitive way to compare discourse patterns across different contexts. By placing bullseye visualizations for different regions or income groups side by side, we can readily observe differences in discourse centralization that might be less apparent in numerical comparisons alone. The bullseye approach is particularly effective for communicating the concept of discourse centralization to non-specialist audiences.</p>
<p>The bullseye visualization can show the degree of centralization but doesn’t directly indicate which topics are prevalent. To address this, I complement the bullseye diagrams with more detailed visualizations that show the specific topics that dominate in different contexts:</p>
<ul>
<li><p><strong>Bar charts</strong>: Comparing Dominance Index values across different groupings to identify variations in overall centralization.</p></li>
<li><p><strong>Heatmaps</strong>: Showing the prevalence of specific topics across different contexts to identify which topics dominate in which contexts.</p></li>
<li><p><strong>Network visualizations</strong>: Illustrating relationships between topics and document characteristics to reveal patterns of association.</p></li>
</ul>
<p>[visualization placeholder - topic prevalence heatmap]</p>
<p>These visualizations help bridge the gap between the abstract metric of the Dominance Index and the substantive content of the discourse. They enable identification of both patterns of centralization (how concentrated the discourse is) and patterns of content (which specific topics dominate in which contexts).</p>
<p>The interpretation of these patterns draws on the theoretical framework developed in the previous chapter. I analyze how discourse centralization relates to epistemological diversity, examining whether differences in Dominance Index values across contexts reflect meaningful variations in how adaptation is conceptualized. This interpretation involves several layers of analysis:</p>
<ol type="1">
<li><p><strong>Pattern identification</strong>: Identifying variations in the Dominance Index across different groupings and assessing their statistical significance.</p></li>
<li><p><strong>Content analysis</strong>: Examining which specific topics dominate in different contexts and how these topics relate to different epistemological and ontological perspectives.</p></li>
<li><p><strong>Contextual interpretation</strong>: Considering how patterns of discourse centralization might relate to broader factors such as regional knowledge systems, institutional frameworks, or historical legacies.</p></li>
<li><p><strong>Theoretical connection</strong>: Relating the empirical findings to theoretical concepts such as epistemological diversity, ontological assumptions, and the politics of scale.</p></li>
</ol>
<p>This interpretive process aims to move beyond simple description of discourse patterns to deeper analysis of their implications for climate adaptation governance. It seeks to connect the “what” (patterns of discourse centralization) to the “why” (factors that might explain these patterns) and the “so what” (implications for just and effective adaptation).</p>
<p>The interpretation explicitly considers alternative explanations for observed patterns. For example, if regional groups show different Dominance Index values, this could reflect:</p>
<ul>
<li>Genuinely different epistemological traditions across regions</li>
<li>Institutional factors such as regional development banks or policy frameworks</li>
<li>Historical patterns of knowledge exchange and policy diffusion</li>
<li>Artifacts of the corpus composition or analytical method</li>
</ul>
<p>By considering these alternatives, I aim to develop more robust interpretations that acknowledge the complexity of factors shaping adaptation discourse.</p>
<p>Throughout this interpretive process, I maintain awareness of what this methodological approach can and cannot tell us. The analysis can identify patterns of topic distribution across different contexts and suggest possible factors influencing these patterns. It cannot definitively establish causal relationships or directly measure epistemological diversity. The findings should be understood as evidence-based insights that can inform further research and policy discussions, rather than as final conclusions about the nature of adaptation discourse.</p>
<p>Despite these limitations, this methodological approach offers valuable insights into patterns of discourse centralization that would be difficult to discern through manual analysis alone. By combining computational methods with critical theoretical perspectives, it contributes to our understanding of how adaptation is conceptualized across different contexts and what factors might influence these conceptualizations. These insights have implications for both academic understandings of adaptation discourse and practical efforts to promote more just and effective adaptation governance.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-roberts2019" class="csl-entry" role="listitem">
Roberts, M. E., Stewart, B. M., &amp; Tingley, D. (2019). Stm: An r package for structural topic models. <em>Journal of Statistical Software</em>, <em>91</em>, 1–40. <a href="https://doi.org/10.18637/jss.v091.i02">https://doi.org/10.18637/jss.v091.i02</a>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../text/theory.html" class="pagination-link" aria-label="Theory: Development Ontology and Epistemological Diversity">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Theory: Development Ontology and Epistemological Diversity</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../text/findings.html" class="pagination-link" aria-label="Findings">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Findings</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>